{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edeaa382-68ff-468e-bb7e-db0c834412d1",
   "metadata": {},
   "source": [
    "This script is used to produce Figure 5 (changes in bloom start and end and daily NPP at individual locations) for the Payne et al. paper \"End-of-century Arctic Ocean phytoplankton blooms start a month earlier due to anthropogenic climate change\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fdabd2-99c0-4946-b064-a358b632ec23",
   "metadata": {},
   "source": [
    "1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd83e7e-c141-46eb-bcc9-3ea88e5ed6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import xarray as xr\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import cmocean\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.path as mpath\n",
    "import xesmf as xe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9093cdf4-6200-43cf-9d43-0f5dd27c9f9d",
   "metadata": {},
   "source": [
    "2. Read in a randomly chosen NPP file. This is used to generate latitude (lat) and longitude (lon) fields for CESM files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8656bf0-260a-4796-8473-c78b57c1a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdir = 'ocn' # 'ocn' or 'ice'\n",
    "vnam = 'photoC_diat_zint_2'#, 'photoC_diaz_zint', 'photoC_sp_zint']#,'photoC_diaz_zint','photoC_sp_zint'] # 'aice' # 'SST'\n",
    "fdir = '/glade/campaign/cgd/cesm/CESM2-LE/'+ vdir + '/proc/tseries/day_1/' + vnam + '/'\n",
    "\n",
    "fnam = 'b.e21.BSSP370cmip6.f09_g17.LE2-1301.003.pop.h.ecosys.nday1.photoC_diat_zint_2.20450102-20550101.nc'\n",
    "\n",
    "ncfile = xr.open_dataset(fdir + fnam)\n",
    "lon = ncfile.TLONG.values\n",
    "lat = ncfile.TLAT.values\n",
    "\n",
    "ok = ~np.isnan(lon)\n",
    "xp = ok.ravel().nonzero()[0]\n",
    "fp = lon[~np.isnan(lon)]\n",
    "x  = np.isnan(lon).ravel().nonzero()[0]\n",
    "lon[np.isnan(lon)] = np.interp(x, xp, fp)\n",
    "\n",
    "ok = ~np.isnan(lat)\n",
    "xp = ok.ravel().nonzero()[0]\n",
    "fp = lat[~np.isnan(lat)]\n",
    "x  = np.isnan(lat).ravel().nonzero()[0]\n",
    "lat[np.isnan(lat)] = np.interp(x, xp, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e146f8-b08b-4f62-8658-2b636cfcddc1",
   "metadata": {},
   "source": [
    "3. Make the areacello_ocn array that gives the area (in m2) of each grid cell in the larger region (latitude > 50Â°N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3440832-b60a-4433-bf91-9728dc2db546",
   "metadata": {},
   "outputs": [],
   "source": [
    "acdir = '/glade/collections/cmip/CMIP6/CMIP/NCAR/CESM2/historical/r1i1p1f1/Ofx/areacello/gn/files/d20190308/areacello_Ofx_CESM2_historical_r1i1p1f1_gn.nc'\n",
    "acfil = xr.open_dataset(acdir)\n",
    "areacello = acfil['areacello'].values # tarea <- ocean files\n",
    "areacello_ocn = np.full([384,320], np.nan)\n",
    "areacello_arc = np.full([384,320], np.nan)\n",
    "for i in np.arange(0,384):\n",
    "    for j in np.arange(0,320):\n",
    "        if np.isnan(ncfile['photoC_diat_zint_2'][180,i,j]) == False and ncfile[\"TLAT\"][i,j] > 50:\n",
    "            areacello_ocn[i,j] = areacello[i,j]\n",
    "        if np.isnan(ncfile['photoC_diat_zint_2'][180,i,j]) == False and ncfile[\"TLAT\"][i,j] > 66.5:\n",
    "            areacello_arc[i,j] = areacello[i,j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eb80c0-b50f-432e-95e1-e2e206c4a698",
   "metadata": {},
   "source": [
    "4. Read in bloom start (max_25) and end (max_25_2) files and npp during the bloom (npp_bloom) and total annual npp (npp_tot). These files were created for each year and across all ensemble members using the \"BloomMetrics\" script. Bloom start occurs on the date when biomass first surpasses 25% of the maximum biomass at any given grid cell, and end occurs on the date when biomass first diminishes below 25% of the maximum following the peak in biomass. I then set any zero values to 'nan'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34fc6e-148c-43d2-9dd6-a6024816422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_25 = np.zeros([14,384,320,50]); max_100 = np.zeros([14,384,320,50]); max_25_2 = np.zeros([14,384,320,50]); \n",
    "npp_tot = np.zeros([14,384,320,50]); npp_bloom = np.zeros([14,384,320,50]); \n",
    "for yrset in np.arange(0,14):\n",
    "    yrnum = str(1970 + yrset*10)\n",
    "    dir = np.loadtxt(\"/glade/u/home/cpayne/Projects/BloomLength/AnnualGC/\" + yrnum + \"_max_25.txt\")\n",
    "    max_25[yrset,:,:,:] = dir.reshape(384,320,50)\n",
    "    dir = np.loadtxt(\"/glade/u/home/cpayne/Projects/BloomLength/AnnualGC/\" + yrnum + \"_max_25_2.txt\")\n",
    "    max_25_2[yrset,:,:,:] = dir.reshape(384,320,50)\n",
    "    dir = np.loadtxt(\"/glade/u/home/cpayne/Projects/BloomLength/AnnualGC/\" + yrnum + \"_npp_bloom.txt\")\n",
    "    npp_bloom[yrset,:,:,:] = dir.reshape(384,320,50)\n",
    "    dir = np.loadtxt(\"/glade/u/home/cpayne/Projects/BloomLength/AnnualGC/\" + yrnum + \"_npp_tot.txt\")\n",
    "    npp_tot[yrset,:,:,:] = dir.reshape(384,320,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8e830-1d81-4c1f-9a64-38dd42f1d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_25 = np.where(max_25==0, np.nan, max_25)\n",
    "max_100 = np.where(max_100==0, np.nan, max_100)\n",
    "max_25_2 = np.where(max_25_2==0, np.nan, max_25_2)\n",
    "npp_bloom = np.where(npp_bloom==0, np.nan, npp_bloom)\n",
    "npp_tot = np.where(npp_tot==0, np.nan, npp_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b8078-942b-44af-870b-5612e5cdefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_50 = np.zeros([50]); var_66 = np.zeros([50])\n",
    "for ens in np.arange(0,50):\n",
    "    var_50[ens] = np.nansum((max_25_2[0,:,:,ens]-max_25[0,:,:,ens]) * areacello_ocn)/np.nansum(areacello_ocn)\n",
    "    var_66[ens] = np.nansum((max_25_2[0,:,:,ens]-max_25[0,:,:,ens]) * areacello_arc)/np.nansum(areacello_arc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ecc4c-e341-4a1e-a021-a4296a748078",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(var_50), np.std(var_50), np.mean(var_66), np.std(var_66))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf857991-7e83-4dcd-9f6a-86d846f1559c",
   "metadata": {},
   "source": [
    "5. Here, I read in the sea ice mask and then I regrid the sea ice files to an even grid, which allows me to plot them as contours on the bloom importance maps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b215882-e7bf-483c-9a88-9d86120b65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Read in a shapefile of the sea ice masks (perennial ice, seasonal ice, open water)\n",
    "ds_simask = xr.open_dataset('/glade/u/home/cpayne/Projects/BloomLength/Input/simask.nc')\n",
    "si_clim = ds_simask[\"si_clim\"]\n",
    "si_ens = ds_simask[\"si_ens\"]\n",
    "\n",
    "# load the xarray lat/lon files from pop grid\n",
    "TLONG = ncfile.TLONG\n",
    "TLAT = ncfile.TLAT\n",
    "\n",
    "# Rename TLON and TLAT coordinates to be lon and lat so we can join them with sea ice data\n",
    "TLONG = TLONG.rename({'nlon':'lon','nlat':'lat'})\n",
    "TLAT =  TLAT.rename({'nlon':'lon','nlat':'lat'})\n",
    "\n",
    "# reset sea ice lat/lon coordinates since TLON looks weird (above)\n",
    "si_clim['TLON'] = TLONG\n",
    "si_clim['TLAT'] = TLAT\n",
    "\n",
    "si_ens['TLON'] = TLONG\n",
    "si_ens['TLAT'] = TLAT\n",
    "\n",
    "#Now rename TLON and TLAT coordinates to be lon and lat because regridders needs that specific naming\n",
    "si_clim = si_clim.rename({'TLON':'lon','TLAT':'lat'})\n",
    "si_ens = si_ens.rename({'TLON':'lon','TLAT':'lat'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd02e88-dce9-4854-8284-1c9192651204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a target grid \n",
    "# Do not include 90N and 90S otherwise cartopy gets rage-y (i.e. it doesn't work) when plotting\n",
    "lat_new = np.arange(-89.5,90.0,0.5) \n",
    "lon_new = np.arange(0.0,361.0,1.0)\n",
    "\n",
    "#create a meshgrid (2D fields of lats and lons)\n",
    "lon2d,lat2d=np.meshgrid(lon_new,lat_new) \n",
    "#set up the target grid as an xarray Dataset\n",
    "target_grid=xr.Dataset({'lat': (['y', 'x'], lat2d),'lon': (['y', 'x'], lon2d)})\n",
    "\n",
    "#input grid, output grid, method, keyword arguments\n",
    "regridder = xe.Regridder(si_clim, target_grid, 'nearest_s2d',periodic=True,reuse_weights=False)\n",
    "\n",
    "# actually do the regridding\n",
    "si_clim_regrid = regridder(si_clim)\n",
    "si_ens_regrid = regridder(si_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f97e84-b9a6-49d1-a572-55e2e0ae1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885efc0-2fb9-4e10-acfb-2074f7bde1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 322; j = 193; # Bering\n",
    "np.nanmean(np.nanmean(si_ens[:,5,317:327,188:198],axis=1),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c9f13-06de-4af7-8bca-ba5b984d4ea3",
   "metadata": {},
   "source": [
    "6. Here, I choose the data I want to plot across the Arctic. I use 'yr2' to control the year I compare to 1970 (=0) and 'vari' and 'vari2' to control which variable I analyze. Bloom start = max_25, bloom end = max_25_2, and bloom length = max_25_2 - max_25. I exclude data where the t-test reveals that the p value is >0.05, indicating an statistically insignificant difference in the variable between the two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531180a-fae4-4170-a90f-b736d0314667",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr2 = 13 # 5 = 2020, 8 = 2050, 13 = 2100\n",
    "data_plt = np.round(np.nanmean(si_ens_regrid[:,0,:,:],axis=0),0)\n",
    "data_plt2 = np.round(np.nanmean(si_ens_regrid[:,yr2,:,:],axis=0),0)\n",
    "vari = max_25_2[0,:,:,:]-max_25[0,:,:,:]\n",
    "vari2 = max_25_2[yr2,:,:,:]-max_25[yr2,:,:,:]\n",
    "varichange = np.full([384,320],np.nan)\n",
    "for i in np.arange(0,384):\n",
    "    for j in np.arange(0,320):\n",
    "        if np.isnan(areacello_ocn[i,j]) == False:\n",
    "            ttest = stats.ttest_rel(vari[i,j,:], vari2[i,j,:])\n",
    "            if ttest.pvalue < 0.05:\n",
    "                varichange[i,j] = np.nanmean(vari2[i,j,:]) - np.nanmean(vari[i,j,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea78a37-18f4-4838-ae2c-9907b3bdf2f1",
   "metadata": {},
   "source": [
    "7. Here I plot Fig 4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1087da-2d17-4a64-b17e-232c7a4c7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make circular boundary for polar stereographic circular plots\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "# set figure basics (size, projection)\n",
    "fig = plt.figure(figsize=(3,3)) \n",
    "ax = plt.axes(projection=ccrs.NorthPolarStereo()); \n",
    "ax.set_boundary(circle, transform=ax.transAxes)\n",
    "ax.set_extent([-180, 180, 50, 90], crs = ccrs.PlateCarree());\n",
    "\n",
    "# make the background stippled throughout the region\n",
    "plt.rcParams['hatch.color'] = 'darkgray'\n",
    "ax.contourf(lon, lat, areacello,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            colors='none', edgecolor = 'grey',\n",
    "            # levels = [.9,1.1],\n",
    "            zorder = 0,\n",
    "            hatches=['...'])\n",
    "\n",
    "# plot changes in the actual variable of interest on top\n",
    "pc = ax.pcolormesh(lon, lat, varichange, \n",
    "                   transform=ccrs.PlateCarree(), vmin = -60, vmax = 60, cmap='coolwarm', zorder = 1);\n",
    "\n",
    "# plot points of interest (locations of data used in Figures 5C-F.\n",
    "plt.scatter(189,72.5,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Chukchi\n",
    "plt.scatter(275.6,58.9,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Hudson\n",
    "plt.scatter(181.2,60.95,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Bering\n",
    "plt.scatter(289.4,85.9,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =3) #Central Arctic\n",
    "\n",
    "# add land and colorbar\n",
    "ax.coastlines();  ax.add_feature(cfeature.LAND,zorder=2); #plt.colorbar(pc, orientation='horizontal', extend='both');\n",
    "plt.colorbar(pc, orientation='vertical', extend='both');\n",
    "\n",
    "# write out figure\n",
    "# figdir = '/glade/u/home/cpayne/Projects/BloomLength/Figures/Fig5a.png';\n",
    "figdir = '/glade/u/home/cpayne/Projects/BloomLength/PresentationFigs/Central.png';\n",
    "plt.savefig(figdir,facecolor='none', dpi = 600);\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d09b18-7748-44b9-8f78-fae44933ed8e",
   "metadata": {},
   "source": [
    "8. Here, I choose the data I want to plot across the Arctic by comparing changes in standard deviation. I use 'yr2' to control the year I compare to 1970 (=0) and 'vari' and 'vari2' to control which variable I analyze. Bloom start = max_25, bloom end = max_25_2, and bloom length = max_25_2 - max_25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3edcc0-9e67-48f9-b89a-2118a159922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr2 = 13 # 5 = 2020, 8 = 2050, 13 = 2100\n",
    "data_plt = np.round(np.nanmean(si_ens_regrid[:,0,:,:],axis=0),0)\n",
    "data_plt2 = np.round(np.nanmean(si_ens_regrid[:,yr2,:,:],axis=0),0)\n",
    "vari = max_25_2[0,:,:,:]-max_25[0,:,:,:]\n",
    "vari2 = max_25_2[yr2,:,:,:]-max_25[yr2,:,:,:]\n",
    "varichange = np.full([384,320],np.nan)\n",
    "for i in np.arange(0,384):\n",
    "    for j in np.arange(0,320):\n",
    "        if np.isnan(areacello_ocn[i,j]) == False:\n",
    "            ttest = stats.ttest_rel(vari[i,j,:], vari2[i,j,:])\n",
    "            if ttest.pvalue < 0.05:\n",
    "                varichange[i,j] = np.nanstd(vari2[i,j,:]) - np.nanstd(vari[i,j,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc10527-ac92-43c3-9878-2d85914dc873",
   "metadata": {},
   "source": [
    "9. Here, I plot Figure 5B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea633ca-c0eb-4b13-8c9e-27dd6f7ee8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make circular boundary for polar stereographic circular plots\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "# set figure basics (size, projection)\n",
    "fig = plt.figure(figsize=(3,3)) \n",
    "ax = plt.axes(projection=ccrs.NorthPolarStereo()); \n",
    "ax.set_boundary(circle, transform=ax.transAxes)\n",
    "ax.set_extent([-180, 180, 50, 90], crs = ccrs.PlateCarree());\n",
    "\n",
    "# plot changes in the actual variable of interest on top\n",
    "pc = ax.pcolormesh(lon, lat, np.std(vari2,axis=2) - np.std(vari,axis=2), \n",
    "                   transform=ccrs.PlateCarree(), vmin = -20, vmax = 20, cmap='BrBG_r');   \n",
    "\n",
    "# plot points of interest (locations of data used in Figures 5C-F.\n",
    "plt.scatter(189,72.5,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Chukchi\n",
    "# plt.scatter(346.1,71.2,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Greenland\n",
    "plt.scatter(275.6,58.9,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Hudson\n",
    "plt.scatter(181.2,60.95,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Bering\n",
    "plt.scatter(289.4,85.9,transform=ccrs.PlateCarree(), facecolors='none', edgecolors='k', linewidth =2) #Central Arctic\n",
    "\n",
    "# add land on top and colorbar\n",
    "ax.coastlines();  ax.add_feature(cfeature.LAND); #plt.colorbar(pc, orientation='horizontal', extend='both');\n",
    "\n",
    "# print this figure\n",
    "figdir = '/glade/u/home/cpayne/Projects/BloomLength/Figures/Fig5b.png';\n",
    "plt.savefig(figdir,facecolor='none', dpi = 600);\n",
    "# # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c47879-6f47-4743-bf23-a92b4bf50c21",
   "metadata": {},
   "source": [
    "10. Read in 1970, 2020, and 2100 daily NPP data (these steps takes a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a29829-eeba-4255-9da0-4ff1e21e31f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a. Select variable of interest and locate the files\n",
    "vdir = 'ocn' # 'ocn' or 'ice'\n",
    "vnam = ['photoC_diat_zint_2','photoC_diaz_zint_2','photoC_sp_zint_2']#['diatC_zint_100m', 'diazC_zint_100m', 'spC_zint_100m']# # 'aice' # 'SST'\n",
    "npp_clim1970 = np.full([50, 365, 384, 320], np.nan)\n",
    "for j in np.arange(0,len(vnam)):\n",
    "    fdir = '/glade/campaign/cgd/cesm/CESM2-LE/'+ vdir + '/proc/tseries/day_1/' + vnam[j] + '/'\n",
    "\n",
    "# b. Make an array of nans to store the values from all EMs\n",
    "    i = -1\n",
    "    \n",
    "# c. Loop through all the files in the directory, storing data in dat_clim\n",
    "    for file in glob.glob(fdir + \"*smbb*19700102*\"): #use suffix 0102 for every year but 2015 and 0101 for 2015.\n",
    "        i = i + 1\n",
    "        if i == 0:\n",
    "            print(file)\n",
    "\n",
    "# d. Open the netcdf and store the variable of interest as dat. Also open lon and lat.\n",
    "        ncfile = xr.open_dataset(file) \n",
    "        dat = ncfile[vnam[j]].values\n",
    "        lon, lat = ncfile.TLONG.values, ncfile.TLAT.values #if in 'ice', use 'TLON', in 'ocn', use 'TLONG'\n",
    "\n",
    "# e. Interpolate lat and lon values over holes in the arrays\n",
    "        ok = ~np.isnan(lon)\n",
    "        xp = ok.ravel().nonzero()[0]\n",
    "        fp = lon[~np.isnan(lon)]\n",
    "        x  = np.isnan(lon).ravel().nonzero()[0]\n",
    "        lon[np.isnan(lon)] = np.interp(x, xp, fp)\n",
    "\n",
    "        ok = ~np.isnan(lat)\n",
    "        xp = ok.ravel().nonzero()[0]\n",
    "        fp = lat[~np.isnan(lat)]\n",
    "        x  = np.isnan(lat).ravel().nonzero()[0]\n",
    "        lat[np.isnan(lat)] = np.interp(x, xp, fp)\n",
    "# f. Loop through the ensemble members, assigning each to its own column.\n",
    "        if j == 0:\n",
    "            for t in range(0,365):\n",
    "                npp_clim1970[i,t,:,:] = dat[t,:,:]#[t+1825,:,:] #Get the year that is 5 years in (e.g. 2050)\n",
    "        else:\n",
    "            for t in range(0,365):\n",
    "                npp_clim1970[i,t,:,:] = dat[t,:,:] + npp_clim1970[i,t,:,:]#dat[t+1825,:,:] + dat_clim[i,t,:,:] #Get the year that is 5 years in (e.g. 2050)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec98e65-efba-424b-8306-cd3b8cbbbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a. Select variable of interest and locate the files\n",
    "vdir = 'ocn' # 'ocn' or 'ice'\n",
    "vnam = ['photoC_diat_zint_2','photoC_diaz_zint_2','photoC_sp_zint_2']#['diatC_zint_100m', 'diazC_zint_100m', 'spC_zint_100m']# # 'aice' # 'SST'\n",
    "npp_clim2020 = np.full([50, 365, 384, 320], np.nan)\n",
    "for j in np.arange(0,len(vnam)):\n",
    "    fdir = '/glade/campaign/cgd/cesm/CESM2-LE/'+ vdir + '/proc/tseries/day_1/' + vnam[j] + '/'\n",
    "\n",
    "# b. Make an array of nans to store the values from all EMs\n",
    "    i = -1\n",
    "    \n",
    "# c. Loop through all the files in the directory, storing data in dat_clim\n",
    "    for file in glob.glob(fdir + \"*smbb*20150101*\"): #use suffix 0102 for every year but 2015 and 0101 for 2015.\n",
    "        i = i + 1\n",
    "        if i == 0:\n",
    "            print(file)\n",
    "\n",
    "# d. Open the netcdf and store the variable of interest as dat. Also open lon and lat.\n",
    "        ncfile = xr.open_dataset(file) \n",
    "        dat = ncfile[vnam[j]].values\n",
    "        lon, lat = ncfile.TLONG.values, ncfile.TLAT.values #if in 'ice', use 'TLON', in 'ocn', use 'TLONG'\n",
    "\n",
    "# e. Interpolate lat and lon values over holes in the arrays\n",
    "        ok = ~np.isnan(lon)\n",
    "        xp = ok.ravel().nonzero()[0]\n",
    "        fp = lon[~np.isnan(lon)]\n",
    "        x  = np.isnan(lon).ravel().nonzero()[0]\n",
    "        lon[np.isnan(lon)] = np.interp(x, xp, fp)\n",
    "\n",
    "        ok = ~np.isnan(lat)\n",
    "        xp = ok.ravel().nonzero()[0]\n",
    "        fp = lat[~np.isnan(lat)]\n",
    "        x  = np.isnan(lat).ravel().nonzero()[0]\n",
    "        lat[np.isnan(lat)] = np.interp(x, xp, fp)\n",
    "# f. Loop through the ensemble members, assigning each to its own column.\n",
    "        if j == 0:\n",
    "            for t in range(0,365):\n",
    "                npp_clim2020[i,t,:,:] = dat[t+1825,:,:]#[t+1825,:,:] #Get the year that is 5 years in (e.g. 2050)\n",
    "            #dat_diat[i,:,:] = np.nansum(dat[1825:3650,:,:], axis = 0)\n",
    "        else:\n",
    "            for t in range(0,365):\n",
    "                npp_clim2020[i,t,:,:] = dat[t+1825,:,:] + npp_clim2020[i,t,:,:]#dat[t+1825,:,:] + dat_clim[i,t,:,:] #Get the year that is 5 years in (e.g. 2050)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0e64d-3dc5-4bb9-9bf7-e934d93d0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a. Select variable of interest and locate the files\n",
    "vdir = 'ocn' # 'ocn' or 'ice'\n",
    "vnam = ['photoC_diat_zint_2','photoC_diaz_zint_2','photoC_sp_zint_2']#['diatC_zint_100m', 'diazC_zint_100m', 'spC_zint_100m']# # 'aice' # 'SST'\n",
    "npp_clim2100 = np.full([50, 365, 384, 320], np.nan)\n",
    "for j in np.arange(0,len(vnam)):\n",
    "    fdir = '/glade/campaign/cgd/cesm/CESM2-LE/'+ vdir + '/proc/tseries/day_1/' + vnam[j] + '/'\n",
    "\n",
    "# b. Make an array of nans to store the values from all EMs\n",
    "    i = -1\n",
    "    \n",
    "# c. Loop through all the files in the directory, storing data in dat_clim\n",
    "    for file in glob.glob(fdir + \"*smbb*20950102*\"): #use suffix 0102 for every year but 2015 and 0101 for 2015.\n",
    "        i = i + 1\n",
    "        if i == 0:\n",
    "            print(file)\n",
    "\n",
    "# d. Open the netcdf and store the variable of interest as dat. Also open lon and lat.\n",
    "        ncfile = xr.open_dataset(file) \n",
    "        dat = ncfile[vnam[j]].values\n",
    "        lon, lat = ncfile.TLONG.values, ncfile.TLAT.values #if in 'ice', use 'TLON', in 'ocn', use 'TLONG'\n",
    "\n",
    "# e. Interpolate lat and lon values over holes in the arrays\n",
    "        ok = ~np.isnan(lon)\n",
    "        xp = ok.ravel().nonzero()[0]\n",
    "        fp = lon[~np.isnan(lon)]\n",
    "        x  = np.isnan(lon).ravel().nonzero()[0]\n",
    "        lon[np.isnan(lon)] = np.interp(x, xp, fp)\n",
    "\n",
    "        ok = ~np.isnan(lat)\n",
    "        xp = ok.ravel().nonzero()[0]\n",
    "        fp = lat[~np.isnan(lat)]\n",
    "        x  = np.isnan(lat).ravel().nonzero()[0]\n",
    "        lat[np.isnan(lat)] = np.interp(x, xp, fp)\n",
    "# f. Loop through the ensemble members, assigning each to its own column.\n",
    "        if j == 0:\n",
    "            for t in range(0,365):\n",
    "                npp_clim2100[i,t,:,:] = dat[t+1825,:,:]#[t+1825,:,:] #Get the year that is 5 years in (e.g. 2050)\n",
    "            #dat_diat[i,:,:] = np.nansum(dat[1825:3650,:,:], axis = 0)\n",
    "        else:\n",
    "            for t in range(0,365):\n",
    "                npp_clim2100[i,t,:,:] = dat[t+1825,:,:] + npp_clim2100[i,t,:,:]#dat[t+1825,:,:] + dat_clim[i,t,:,:] #Get the year that is 5 years in (e.g. 2050)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea31bc-0bb3-4f47-a7cf-54fc166be4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_clim2020 =npp_clim2020\n",
    "sp_clim2100 =npp_clim2100\n",
    "sp_clim1970 =npp_clim1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded10339-c195-4fcb-92c5-f564f42989e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nansum(np.nanmean(np.nansum(sp_clim1970,axis=1)/np.nansum(npp_clim1970,axis=1),axis=0)*areacello_ocn)/np.nansum(areacello_ocn),\n",
    "     np.nansum(np.nanmean(np.nansum(sp_clim1970,axis=1)/np.nansum(npp_clim1970,axis=1),axis=0)*areacello_arc)/np.nansum(areacello_arc),\n",
    "     np.nansum(np.nanmean(np.nansum(sp_clim2020,axis=1)/np.nansum(npp_clim2020,axis=1),axis=0)*areacello_ocn)/np.nansum(areacello_ocn),\n",
    "     np.nansum(np.nanmean(np.nansum(sp_clim2020,axis=1)/np.nansum(npp_clim2020,axis=1),axis=0)*areacello_arc)/np.nansum(areacello_arc),\n",
    "     np.nansum(np.nanmean(np.nansum(sp_clim2100,axis=1)/np.nansum(npp_clim2100,axis=1),axis=0)*areacello_ocn)/np.nansum(areacello_ocn),\n",
    "     np.nansum(np.nanmean(np.nansum(sp_clim2100,axis=1)/np.nansum(npp_clim2100,axis=1),axis=0)*areacello_arc)/np.nansum(areacello_arc),\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0792a2a-beb2-4d8e-862e-28b18606b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nansum(np.nanmean(np.nansum(diat_clim2100,axis=1)/np.nansum(npp_clim2100,axis=1),axis=0)*areacello_arc)/np.nansum(areacello_arc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced64e73-20c0-4ad0-816c-c11a4826f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nansum(np.nanmean(np.nansum(diat_clim2020,axis=1)/np.nansum(npp_clim2020,axis=1),axis=0)*areacello_ocn)/np.nansum(areacello_ocn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee959b-1597-43a3-8ffc-2af4fab8462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nansum(np.nanmean(np.nansum(diat_clim2100,axis=1)/np.nansum(npp_clim2100,axis=1),axis=0)*areacello_ocn)/np.nansum(areacello_ocn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccfd804-658f-4970-8a3b-72e24e51ef1a",
   "metadata": {},
   "source": [
    "11. Make Figures 4C-F. To do this, copy lines of code from the cell directly below here into the appropriate spots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deda1c89-0057-4f0a-b2c9-c6f75723dc91",
   "metadata": {},
   "source": [
    "Bering: \n",
    "i = 322; j=193; maxvl = .33; \n",
    "plt.yticks([0,0.05,0.1,0.15,0.2,y1970,y2020,y2100], labels = [0,0.05,0.1,0.15,0.2,1970,2020,2100])\n",
    "Chukchi:\n",
    "i = 342; j=194; maxvl = .082; \n",
    "plt.yticks([0,0.01,0.02,0.03,0.04,0.05,y1970,y2020,y2100], labels = [0,0.01,0.02,0.03,0.04,0.05,1970,2020,2100])\n",
    "Hudson: \n",
    "i = 341; j=275; maxvl = .057; \n",
    "plt.yticks([0,0.01,0.02,0.03,0.04,y1970,y2020,y2100], labels = [0,0.01,0.02,0.03,0.04,1970,2020,2100])\n",
    "Central: \n",
    "i = 372; j=176; maxvl = .064; \n",
    "plt.yticks([0,0.01,0.02,0.03,0.04,y1970,y2020,y2100], labels = [0,0.01,0.02,0.03,0.04,1970,2020,2100])\n",
    "Greenland: \n",
    "i = 373; j = 40; maxvl = .175\n",
    "plt.yticks([0,0.04,0.08,0.12,y1970,y2020,y2100], labels = [0,0.04,0.08,0.12,1970,2020,2100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e1ac2-f14d-4b87-8bf5-5de753f0d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy first line of code for desired point here.\n",
    "i = 373; j = 40; maxvl = .175\n",
    "\n",
    "# Set height of bloom metrics data and colors for the plot\n",
    "y1970 = .97*maxvl; y2020 = .89*maxvl; y2100 = .81*maxvl; ln = .77*maxvl\n",
    "rd = '#e41a1c'; pr = '#984ea3'; bl = '#377eb8'\n",
    "\n",
    "# Calculate daily NPP mean and St. Dev. for 1970, 2020, and 2100.\n",
    "mean_1970 = np.mean(npp_clim1970[:,:,i,j],axis=0); sd_1970 = np.std(npp_clim1970[:,:,i,j],axis=0)\n",
    "mean_2020 = np.mean(npp_clim2020[:,:,i,j],axis=0); sd_2020 = np.std(npp_clim2020[:,:,i,j],axis=0)\n",
    "mean_2100 = np.mean(npp_clim2100[:,:,i,j],axis=0); sd_2100 = np.std(npp_clim2100[:,:,i,j],axis=0)\n",
    "\n",
    "# Calculate mean and St. Dev. bloom start and end timing for 1970, 2020, and 2100\n",
    "meanstart_1970 = np.mean(max_25[0,i,j,:]); stdstart_1970 = np.std(max_25[0,i,j,:])\n",
    "meanend_1970 = np.mean(max_25_2[0,i,j,:]); stdend_1970 = np.std(max_25_2[0,i,j,:])\n",
    "meanstart_2020 = np.mean(max_25[5,i,j,:]); stdstart_2020 = np.std(max_25[5,i,j,:])\n",
    "meanend_2020 = np.mean(max_25_2[5,i,j,:]); stdend_2020 = np.std(max_25_2[5,i,j,:])\n",
    "meanstart_2100 = np.mean(max_25[13,i,j,:]); stdstart_2100 = np.std(max_25[13,i,j,:])\n",
    "meanend_2100 = np.mean(max_25_2[13,i,j,:]); stdend_2100 = np.std(max_25_2[13,i,j,:])\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(2,2.5))\n",
    "\n",
    "# Plot daily NPP mean and St. Dev. for each year\n",
    "plt.fill_between(np.arange(1,366),mean_1970 - sd_1970, mean_1970 + sd_1970, \n",
    "                 color=bl,alpha=0.4)\n",
    "plt.plot(np.arange(1,366),mean_1970, color=bl)\n",
    "\n",
    "plt.fill_between(np.arange(1,366),mean_2020 - sd_2020, mean_2020 + sd_2020, \n",
    "                 color=pr,alpha=0.4)\n",
    "plt.plot(np.arange(1,366),mean_2020, color=pr)\n",
    "\n",
    "plt.fill_between(np.arange(1,366),mean_2100 - sd_2100, mean_2100 + sd_2100, \n",
    "                 color=rd,alpha=0.4)\n",
    "plt.plot(np.arange(1,366),mean_2100, color=rd)\n",
    "\n",
    "# Plot bloom start and end timing for each year\n",
    "plt.plot([meanstart_1970-stdstart_1970,meanstart_1970+stdstart_1970],\n",
    "         [y1970,y1970],color = bl, linewidth=2)\n",
    "plt.plot([meanend_1970-stdend_1970,meanend_1970+stdend_1970],\n",
    "         [y1970,y1970],color = bl, linewidth=2)\n",
    "plt.scatter(meanstart_1970,y1970,color = bl, s=20)\n",
    "plt.scatter(meanend_1970,y1970,color = bl, s=20)\n",
    "\n",
    "plt.plot([meanstart_2020-stdstart_2020,meanstart_2020+stdstart_2020],\n",
    "         [y2020,y2020],color = pr, linewidth=2)\n",
    "plt.plot([meanend_2020-stdend_2020,meanend_2020+stdend_2020],\n",
    "         [y2020,y2020],color = pr, linewidth=2)\n",
    "plt.scatter(meanstart_2020,y2020,color = pr, s=20)\n",
    "plt.scatter(meanend_2020,y2020,color = pr, s=20)\n",
    "\n",
    "plt.plot([meanstart_2100-stdstart_2100,meanstart_2100+stdstart_2100],\n",
    "         [y2100,y2100],color = rd, linewidth=2)\n",
    "plt.plot([meanend_2100-stdend_2100,meanend_2100+stdend_2100],\n",
    "         [y2100,y2100],color = rd, linewidth=2)\n",
    "plt.scatter(meanstart_2100,y2100,color = rd, s=20)\n",
    "plt.scatter(meanend_2100,y2100,color = rd, s=20)\n",
    "\n",
    "# Set axis limits\n",
    "plt.ylim(-.0001,maxvl); plt.xlim(-1,366)\n",
    "\n",
    "# Copy second line of code for desired point here.\n",
    "plt.yticks([0,0.04,0.08,0.12,y1970,y2020,y2100], labels = [0,0.04,0.08,0.12,1970,2020,2100])\n",
    "\n",
    "# Set x axis labels and make line to separate upper data from lower\n",
    "plt.xticks([1,32,60,91,121,152,182,213,244,274,305,335], \n",
    "           labels = ['J','F','M','A','M','J','J','A','S','O','N','D'])\n",
    "plt.plot([-1,367],[ln,ln],color='k',linewidth=.8)\n",
    "\n",
    "# write plot out\n",
    "figdir = '/glade/u/home/cpayne/Projects/BloomLength/Figures/Fig5g.png';\n",
    "plt.savefig(figdir,facecolor='none', dpi = 600,bbox_inches=\"tight\");\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705d07c-3ed6-4559-92d3-2ac19344eb0d",
   "metadata": {},
   "source": [
    "12. Print out a ton of information about each point (used in writing the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ebbbb2-4aa8-44c0-9f3b-519f11a30031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 322; j = 193; # Bering\n",
    "# i = 342; j = 194; # Chukchi\n",
    "# i = 341; j = 275; # Hudson\n",
    "# i = 372; j = 176; # Central\n",
    "i = 373; j = 40;  # Greenland\n",
    "\n",
    "print('Greenland')\n",
    "print('Sea Ice 1970:', np.mean(si_ens[:,0,i,j]).values)\n",
    "print('Sea Ice 2020:', np.mean(si_ens[:,5,i,j]).values)\n",
    "print('Sea Ice 2100:', np.mean(si_ens[:,13,i,j]).values)\n",
    "# print('Sea Ice 1970:', si_ens[:,0,i,j].values)\n",
    "# print('Sea Ice 2020:', si_ens[:,5,i,j].values)\n",
    "# print('Sea Ice 2100:', si_ens[:,13,i,j].values)\n",
    "print('.')\n",
    "print('Bloom Start',np.mean(max_25[0,i,j,:],axis=0),np.mean(max_25[5,i,j,:],axis=0),np.mean(max_25[13,i,j,:],axis=0),\n",
    "     np.mean(max_25[13,i,j,:],axis=0)-np.mean(max_25[0,i,j,:],axis=0))\n",
    "print(np.std(max_25[0,i,j,:],axis=0),np.std(max_25[5,i,j,:],axis=0),np.std(max_25[13,i,j,:],axis=0))\n",
    "print(stats.ttest_rel(max_25[0,i,j,:], max_25[5,i,j,:]))\n",
    "print(stats.ttest_rel(max_25[0,i,j,:], max_25[13,i,j,:]))\n",
    "print('.')\n",
    "print('Bloom End',np.mean(max_25_2[0,i,j,:],axis=0),np.mean(max_25_2[5,i,j,:],axis=0),np.mean(max_25_2[13,i,j,:],axis=0),\n",
    "     np.mean(max_25_2[13,i,j,:],axis=0)-np.mean(max_25_2[0,i,j,:],axis=0))\n",
    "print(np.std(max_25_2[0,i,j,:],axis=0),np.std(max_25_2[5,i,j,:],axis=0),np.std(max_25_2[13,i,j,:],axis=0))\n",
    "print(stats.ttest_rel(max_25_2[0,i,j,:], max_25_2[5,i,j,:]))\n",
    "print(stats.ttest_rel(max_25_2[0,i,j,:], max_25_2[13,i,j,:]))\n",
    "print('.')\n",
    "print('Bloom Length',np.mean(max_25_2[0,i,j,:]-max_25[0,i,j,:],axis=0),np.mean(max_25_2[5,i,j,:]-max_25[5,i,j,:],axis=0),np.mean(max_25_2[13,i,j,:]-max_25[13,i,j,:],axis=0),\n",
    "     np.mean(max_25_2[13,i,j,:]-max_25[13,i,j,:],axis=0)-np.mean(max_25_2[0,i,j,:]-max_25[0,i,j,:],axis=0))\n",
    "print(np.std(max_25_2[0,i,j,:]-max_25[13,i,j,:],axis=0),np.std(max_25_2[13,i,j,:]-max_25[0,i,j,:],axis=0))\n",
    "print(stats.ttest_rel(max_25_2[0,i,j,:]-max_25[0,i,j,:], max_25_2[5,i,j,:]-max_25[5,i,j,:]))\n",
    "print(stats.ttest_rel(max_25_2[0,i,j,:]-max_25[0,i,j,:], max_25_2[13,i,j,:]-max_25[13,i,j,:]))\n",
    "print('.')\n",
    "print('Bloom NPP',np.mean(npp_bloom[0,i,j,:],axis=0),np.mean(npp_bloom[5,i,j,:],axis=0),np.mean(npp_bloom[13,i,j,:],axis=0))\n",
    "print(np.std(npp_bloom[0,i,j,:],axis=0),np.std(npp_bloom[5,i,j,:],axis=0),np.std(npp_bloom[13,i,j,:],axis=0))\n",
    "print(stats.ttest_rel(npp_bloom[0,i,j,:],npp_bloom[5,i,j,:]))\n",
    "print(stats.ttest_rel(npp_bloom[0,i,j,:],npp_bloom[13,i,j,:]))\n",
    "print('.')\n",
    "print('Daily Bloom NPP',np.mean(npp_bloom[0,i,j,:]/(max_25_2[0,i,j,:]-max_25[0,i,j,:]),axis=0),\n",
    "                                np.mean(npp_bloom[5,i,j,:]/(max_25_2[5,i,j,:]-max_25[5,i,j,:]),axis=0),\n",
    "                                np.mean(npp_bloom[13,i,j,:]/(max_25_2[13,i,j,:]-max_25[13,i,j,:]),axis=0))\n",
    "print(np.std(npp_bloom[0,i,j,:]/(max_25_2[0,i,j,:]-max_25[0,i,j,:]),axis=0),np.std(npp_bloom[5,i,j,:]/(max_25_2[5,i,j,:]-max_25[5,i,j,:]),axis=0),\n",
    "      np.std(npp_bloom[13,i,j,:]/(max_25_2[13,i,j,:]-max_25[13,i,j,:]),axis=0))\n",
    "print(stats.ttest_rel(npp_bloom[0,i,j,:]/(max_25_2[0,i,j,:]-max_25[0,i,j,:]),npp_bloom[5,i,j,:]/(max_25_2[5,i,j,:]-max_25[5,i,j,:])))\n",
    "print(stats.ttest_rel(npp_bloom[0,i,j,:]/(max_25_2[0,i,j,:]-max_25[0,i,j,:]),npp_bloom[13,i,j,:]/(max_25_2[13,i,j,:]-max_25[13,i,j,:])))\n",
    "print('.')\n",
    "print('Tot NPP',np.mean(npp_tot[0,i,j,:],axis=0),np.mean(npp_tot[5,i,j,:],axis=0),np.mean(npp_tot[13,i,j,:],axis=0))\n",
    "print(np.std(npp_tot[0,i,j,:],axis=0),np.std(npp_tot[5,i,j,:],axis=0),np.std(npp_tot[13,i,j,:],axis=0))\n",
    "print(stats.ttest_rel(npp_tot[0,i,j,:],npp_tot[5,i,j,:]))\n",
    "print(stats.ttest_rel(npp_tot[0,i,j,:],npp_tot[13,i,j,:]))\n",
    "print('.')\n",
    "print('Prop. Bloom NPP',np.mean(npp_bloom[0,i,j,:]/npp_tot[0,i,j,:],axis=0),np.mean(npp_bloom[5,i,j,:]/npp_tot[5,i,j,:],axis=0),\n",
    "      np.mean(npp_bloom[13,i,j,:]/npp_tot[13,i,j,:],axis=0))\n",
    "print(np.std(npp_bloom[0,i,j,:]/npp_tot[0,i,j,:],axis=0),np.std(npp_bloom[5,i,j,:]/npp_tot[5,i,j,:],axis=0),np.std(npp_bloom[13,i,j,:]/npp_tot[13,i,j,:],axis=0))\n",
    "print(stats.ttest_rel(npp_bloom[0,i,j,:]/npp_tot[0,i,j,:],npp_bloom[5,i,j,:]/npp_tot[5,i,j,:]))\n",
    "print(stats.ttest_rel(npp_bloom[0,i,j,:]/npp_tot[0,i,j,:],npp_bloom[13,i,j,:]/npp_tot[13,i,j,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1252fd3-6750-4a1d-b741-4835ddf3cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr = 13\n",
    "npp_50 = np.zeros([50]); npp_66 = np.zeros([50]); \n",
    "for ens in np.arange(0,50):\n",
    "    npp_50[ens] = np.nansum((npp_bloom[yr,:,:,ens]/(max_25_2[yr,:,:,ens]-max_25[yr,:,:,ens]))* areacello_ocn)/np.nansum(areacello_ocn) \n",
    "    npp_66[ens] = np.nansum((npp_bloom[yr,:,:,ens]/(max_25_2[yr,:,:,ens]-max_25[yr,:,:,ens]))* areacello_arc)/np.nansum(areacello_ocn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27c0e4-71cc-410e-85d5-86031bc2082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(npp_50), np.std(npp_50), np.mean(npp_66), np.std(npp_66))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c09a1-011a-4fbf-8515-1cb5cec55c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "npp_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24fdd6-c4be-46c0-805f-cc807b5420fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024b",
   "language": "python",
   "name": "npl-2024b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
